{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tf1_keras_recap.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMvlzaV2D1N3vR7+vfVddzj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"S4o6qqttOLce","colab_type":"text"},"source":["# Short Keras Recap\n","\n","The Keras network developed in this notebook serves as the basis for our subsequent experiments. It is intentionally kept short and concise and is intended as a reference point for those who see TensorFlow code for the first time. In the next step we will train the Keras network developed in this notebook with a DP Optimmizer from the Tensorflow-Privacy Library."]},{"cell_type":"code","metadata":{"id":"9Bv5_w60J64i","colab_type":"code","colab":{}},"source":["# set tensorlfow version in google colab\n","try:\n","  %tensorflow_version 1.x\n","except Exception:\n","  pass\n","import tensorflow.compat.v1 as tf\n","\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xLY2WanILR_z","colab_type":"code","colab":{}},"source":["def load_mnist():\n","  \"\"\"Loads and preprocesses the MNIST dataset.\n","\n","  Returns\n","  -------\n","  tuple\n","      (training data, training labels, test data, test labels)\n","  \"\"\"\n","  train, test = tf.keras.datasets.mnist.load_data()\n","  train_data, train_labels = train\n","  test_data, test_labels = test\n","\n","  train_data = np.array(train_data, dtype=np.float32) / 255\n","  test_data = np.array(test_data, dtype=np.float32) / 255\n","\n","  train_data = train_data.reshape(train_data.shape[0], 28, 28, 1)\n","  test_data = test_data.reshape(test_data.shape[0], 28, 28, 1)\n","\n","  train_labels = np.array(train_labels, dtype=np.int32)\n","  test_labels = np.array(test_labels, dtype=np.int32)\n","\n","  train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=10)\n","  test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=10)\n","\n","  assert train_data.min() == 0.\n","  assert train_data.max() == 1.\n","  assert test_data.min() == 0.\n","  assert test_data.max() == 1.\n","\n","  return train_data, train_labels, test_data, test_labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2QO43cGjKScw","colab_type":"code","colab":{}},"source":["def create_model():\n","  from tensorflow.keras import Sequential\n","  from tensorflow.keras.layers import Conv2D\n","  from tensorflow.keras.layers import MaxPool2D\n","  from tensorflow.keras.layers import Flatten\n","  from tensorflow.keras.layers import Dense\n","  \n","  model = Sequential()\n","  model.add(Conv2D(16, 8, strides=2, padding='same', activation='relu', \n","                   input_shape=(28, 28, 1)))\n","  model.add(MaxPool2D(2, 1))\n","  model.add(Conv2D(32, 4, strides=2, padding='valid', activation='relu'))\n","  model.add(MaxPool2D(2, 1))\n","  model.add(Flatten())\n","  model.add(Dense(32, activation='relu'))\n","  model.add(Dense(10))\n","  \n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nf9Be2yCKjsH","colab_type":"code","colab":{}},"source":["train_data, train_labels, test_data, test_labels = load_mnist()\n","\n","model = create_model()\n","\n","learning_rate = 0.05\n","batch_size = 64\n","epochs = 10\n","\n","optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n","loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n","model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lfdVJxQOLKqa","colab_type":"code","outputId":"5c08d5e9-b174-4ee3-9b7c-dee822d7a600","executionInfo":{"status":"ok","timestamp":1592228232450,"user_tz":-120,"elapsed":58558,"user":{"displayName":"jonas sander","photoUrl":"","userId":"00193758946461779324"}},"colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["history = model.fit(train_data, train_labels,\n","                    epochs=epochs,\n","                    validation_data=(test_data, test_labels),\n","                    batch_size=batch_size,\n","                    verbose=1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/10\n","60000/60000 [==============================] - 10s 172us/sample - loss: 0.3603 - acc: 0.8860 - val_loss: 0.0932 - val_acc: 0.9699\n","Epoch 2/10\n","60000/60000 [==============================] - 4s 74us/sample - loss: 0.0815 - acc: 0.9749 - val_loss: 0.0666 - val_acc: 0.9784\n","Epoch 3/10\n","60000/60000 [==============================] - 4s 74us/sample - loss: 0.0611 - acc: 0.9814 - val_loss: 0.0435 - val_acc: 0.9860\n","Epoch 4/10\n","60000/60000 [==============================] - 4s 75us/sample - loss: 0.0504 - acc: 0.9842 - val_loss: 0.0499 - val_acc: 0.9846\n","Epoch 5/10\n","60000/60000 [==============================] - 5s 75us/sample - loss: 0.0426 - acc: 0.9865 - val_loss: 0.0479 - val_acc: 0.9853\n","Epoch 6/10\n","60000/60000 [==============================] - 4s 74us/sample - loss: 0.0376 - acc: 0.9883 - val_loss: 0.0376 - val_acc: 0.9882\n","Epoch 7/10\n","60000/60000 [==============================] - 4s 75us/sample - loss: 0.0329 - acc: 0.9894 - val_loss: 0.0385 - val_acc: 0.9867\n","Epoch 8/10\n","60000/60000 [==============================] - 4s 74us/sample - loss: 0.0292 - acc: 0.9907 - val_loss: 0.0389 - val_acc: 0.9866\n","Epoch 9/10\n","60000/60000 [==============================] - 4s 74us/sample - loss: 0.0265 - acc: 0.9916 - val_loss: 0.0355 - val_acc: 0.9883\n","Epoch 10/10\n","60000/60000 [==============================] - 5s 75us/sample - loss: 0.0238 - acc: 0.9923 - val_loss: 0.0424 - val_acc: 0.9879\n"],"name":"stdout"}]}]}